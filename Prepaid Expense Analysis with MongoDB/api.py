"""
Prepaid Expense Analysis - API Wrapper for Orchestration
FIXED VERSION - Corrected endpoints and added better logging
Port: 5013
"""

from flask import Flask, request, jsonify, send_file
from werkzeug.utils import secure_filename
import os
import pandas as pd
import io
from datetime import datetime
from decimal import Decimal
import logging
import traceback

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Initialize Flask app
app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB max
app.config['UPLOAD_FOLDER'] = 'temp_uploads'

# Create upload folder
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

ALLOWED_EXTENSIONS = {'xlsx', 'xls', 'csv', 'pdf'}

# Store session results (in production, use Redis)
SESSIONS = {}


def allowed_file(filename):
    """Check if file extension is allowed"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


# ============================================================================
# CORE PROCESSING FUNCTIONS
# ============================================================================

def clean_amount(value):
    """Clean and convert amount string to Decimal"""
    if pd.isna(value):
        return Decimal('0')
    
    amount_str = str(value).strip()
    amount_str = amount_str.replace(',', '').replace('$', '').replace('‚Çπ', '')
    
    if '(' in amount_str and ')' in amount_str:
        amount_str = '-' + amount_str.replace('(', '').replace(')', '')
    
    amount_str = amount_str.strip()
    
    try:
        return Decimal(amount_str)
    except:
        return Decimal('0')


def find_column(df, possible_names):
    """Find a column by checking multiple possible names"""
    df_columns_lower = [str(col).strip().lower().replace(' ', '_').replace('-', '_') for col in df.columns]
    
    for name in possible_names:
        if name in df_columns_lower:
            index = df_columns_lower.index(name)
            return df.columns[index]
    
    return None


def process_gl_file(filepath):
    """Process General Ledger file"""
    try:
        logger.info(f"üìä Processing GL file: {os.path.basename(filepath)}")
        
        # Read file
        if filepath.endswith('.csv'):
            df = pd.read_csv(filepath)
        else:
            df = pd.read_excel(filepath)
        
        # Normalize column names
        df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')
        
        # Find columns
        account_number_col = find_column(df, [
            'account_code', 'account_number', 'account_no', 'acct_no', 
            'acc_no', 'code', 'number', 'account_no.'
        ])
        
        account_name_col = find_column(df, [
            'account_details', 'account_name', 'account_description', 
            'description', 'name', 'details'
        ])
        
        balance_col = find_column(df, [
            'ending_balance', 'balance', 'amount', 'debit', 'credit', 
            'bal', 'end_balance', 'closing_balance'
        ])
        
        if not account_number_col:
            raise ValueError(f"Could not find Account Number column. Available: {list(df.columns)}")
        if not account_name_col:
            raise ValueError(f"Could not find Account Name column. Available: {list(df.columns)}")
        if not balance_col:
            raise ValueError(f"Could not find Balance column. Available: {list(df.columns)}")
        
        logger.info(f"‚úì GL Columns mapped: Number='{account_number_col}', Name='{account_name_col}', Balance='{balance_col}'")
        
        # Filter prepaid accounts
        prepaid_mask = (
            df[account_number_col].astype(str).str.startswith('1', na=False) |
            df[account_name_col].astype(str).str.contains('prepaid', case=False, na=False) |
            df[account_name_col].astype(str).str.contains('deferred', case=False, na=False)
        )
        
        prepaid_df = df[prepaid_mask].copy()
        
        if len(prepaid_df) == 0:
            logger.warning("‚ö† No prepaid accounts found. Processing all accounts.")
            prepaid_df = df.copy()
        
        # Clean and structure data
        gl_data = []
        for _, row in prepaid_df.iterrows():
            if pd.notna(row[account_number_col]) and str(row[account_number_col]).strip() != '':
                gl_data.append({
                    'account_number': str(row[account_number_col]).strip(),
                    'account_name': str(row[account_name_col]).strip() if pd.notna(row[account_name_col]) else '',
                    'balance': clean_amount(row[balance_col])
                })
        
        logger.info(f"‚úÖ GL processed: {len(gl_data)} prepaid accounts")
        return gl_data
        
    except Exception as e:
        logger.error(f"‚ùå GL processing error: {str(e)}")
        raise


def process_tb_file(filepath):
    """Process Trial Balance file"""
    try:
        logger.info(f"üìä Processing TB file: {os.path.basename(filepath)}")
        
        # Read file
        if filepath.endswith('.csv'):
            df = pd.read_csv(filepath)
        else:
            df = pd.read_excel(filepath)
        
        # Normalize column names
        df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')
        
        # Find columns (same as GL)
        account_number_col = find_column(df, [
            'account_code', 'account_number', 'account_no', 'acct_no', 
            'acc_no', 'code', 'number', 'account_no.'
        ])
        
        account_name_col = find_column(df, [
            'account_details', 'account_name', 'account_description', 
            'description', 'name', 'details'
        ])
        
        balance_col = find_column(df, [
            'ending_balance', 'balance', 'amount', 'debit', 'credit', 
            'bal', 'end_balance', 'closing_balance'
        ])
        
        if not account_number_col or not account_name_col or not balance_col:
            raise ValueError("Could not find required columns in TB file")
        
        logger.info(f"‚úì TB Columns mapped: Number='{account_number_col}', Name='{account_name_col}', Balance='{balance_col}'")
        
        # Filter prepaid accounts
        prepaid_mask = (
            df[account_number_col].astype(str).str.startswith('1', na=False) |
            df[account_name_col].astype(str).str.contains('prepaid', case=False, na=False) |
            df[account_name_col].astype(str).str.contains('deferred', case=False, na=False)
        )
        
        prepaid_df = df[prepaid_mask].copy()
        
        if len(prepaid_df) == 0:
            logger.warning("‚ö† No prepaid accounts found. Processing all accounts.")
            prepaid_df = df.copy()
        
        # Clean and structure data
        tb_data = []
        for _, row in prepaid_df.iterrows():
            if pd.notna(row[account_number_col]) and str(row[account_number_col]).strip() != '':
                tb_data.append({
                    'account_number': str(row[account_number_col]).strip(),
                    'account_name': str(row[account_name_col]).strip() if pd.notna(row[account_name_col]) else '',
                    'balance': clean_amount(row[balance_col])
                })
        
        logger.info(f"‚úÖ TB processed: {len(tb_data)} prepaid accounts")
        return tb_data
        
    except Exception as e:
        logger.error(f"‚ùå TB processing error: {str(e)}")
        raise


def process_invoice_file(filepath):
    """Process Invoice file"""
    try:
        logger.info(f"üìÑ Processing Invoice file: {os.path.basename(filepath)}")
        
        # Read file
        if filepath.endswith('.csv'):
            df = pd.read_csv(filepath)
        else:
            df = pd.read_excel(filepath)
        
        # Normalize column names
        df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')
        
        # Find columns
        invoice_number_col = find_column(df, [
            'invoice_number', 'invoice_no', 'inv_no', 'number', 'num', 'invoice'
        ])
        
        date_col = find_column(df, [
            'date', 'invoice_date', 'inv_date', 'transaction_date'
        ])
        
        amount_col = find_column(df, [
            'amount', 'total', 'invoice_amount', 'ending_balance', 'balance', 'due'
        ])
        
        category_col = find_column(df, [
            'category', 'prepaid_expense_category', 'expense_category', 
            'type', 'description', 'item', 'account_name'
        ])
        
        account_number_col = find_column(df, [
            'account_code', 'account_number', 'account_no', 'acct_no', 'code'
        ])
        
        if not invoice_number_col or not date_col or not amount_col:
            raise ValueError("Could not find required columns in Invoice file")
        
        if not category_col:
            logger.warning("‚ö† No category column found. Using 'Uncategorized'")
            df['category'] = 'Uncategorized'
            category_col = 'category'
        
        logger.info(f"‚úì Invoice Columns mapped: Invoice#='{invoice_number_col}', Date='{date_col}', Amount='{amount_col}'")
        
        # Clean and structure data
        invoice_data = []
        for _, row in df.iterrows():
            if pd.notna(row[invoice_number_col]) and str(row[invoice_number_col]).strip() != '':
                try:
                    invoice_data.append({
                        'invoice_number': str(row[invoice_number_col]).strip(),
                        'date': pd.to_datetime(row[date_col]).date() if pd.notna(row[date_col]) else datetime.now().date(),
                        'amount': clean_amount(row[amount_col]),
                        'category': str(row[category_col]).strip() if pd.notna(row[category_col]) else 'Uncategorized',
                        'account_number': str(row[account_number_col]).strip() if account_number_col and pd.notna(row[account_number_col]) else None
                    })
                except Exception as e:
                    logger.warning(f"‚ö† Skipping invoice row: {e}")
                    continue
        
        logger.info(f"‚úÖ Invoices processed: {len(invoice_data)} records")
        return invoice_data
        
    except Exception as e:
        logger.error(f"‚ùå Invoice processing error: {str(e)}")
        raise


def analyze_prepaid_expenses(gl_data, tb_data, invoice_data, materiality_threshold=100.00):
    """
    Analyze prepaid expenses by comparing GL, TB, and recalculated amounts
    """
    try:
        logger.info("üîç Running prepaid expense analysis...")
        
        # Convert to dictionaries for lookup
        gl_dict = {item['account_number']: item for item in gl_data}
        tb_dict = {item['account_number']: item for item in tb_data}
        
        # Group invoices by account
        invoice_groups = {}
        for invoice in invoice_data:
            account_number = None
            
            # Try to match by account number
            if invoice['account_number'] and invoice['account_number'] in gl_dict:
                account_number = invoice['account_number']
            else:
                # Try to match by category
                category_lower = invoice['category'].lower()
                for acc_num, acc_data in gl_dict.items():
                    account_name_lower = acc_data['account_name'].lower()
                    if any(word in account_name_lower for word in category_lower.split()):
                        account_number = acc_num
                        break
            
            if account_number:
                if account_number not in invoice_groups:
                    invoice_groups[account_number] = []
                invoice_groups[account_number].append(invoice)
        
        # Analyze each account
        analysis_results = []
        discrepancies = []
        
        all_accounts = set(gl_dict.keys()) | set(tb_dict.keys())
        
        for account_number in all_accounts:
            gl_entry = gl_dict.get(account_number)
            tb_entry = tb_dict.get(account_number)
            
            account_name = (gl_entry['account_name'] if gl_entry else 
                           tb_entry['account_name'] if tb_entry else 
                           'Unknown Account')
            
            gl_balance = gl_entry['balance'] if gl_entry else Decimal('0')
            tb_balance = tb_entry['balance'] if tb_entry else Decimal('0')
            
            # Calculate expected balance (simplified: 50% of invoice total)
            recalculated_balance = Decimal('0')
            if account_number in invoice_groups:
                total_invoices = sum(inv['amount'] for inv in invoice_groups[account_number])
                recalculated_balance = total_invoices * Decimal('0.5')
            
            discrepancy_gl = gl_balance - recalculated_balance if gl_entry else None
            discrepancy_tb = tb_balance - recalculated_balance if tb_entry else None
            
            # Create analysis record
            analysis = {
                'account_number': account_number,
                'account_name': account_name,
                'gl_balance': float(gl_balance),
                'tb_balance': float(tb_balance),
                'recalculated_balance': float(recalculated_balance),
                'discrepancy_gl': float(discrepancy_gl) if discrepancy_gl else 0,
                'discrepancy_tb': float(discrepancy_tb) if discrepancy_tb else 0,
                'invoice_count': len(invoice_groups.get(account_number, []))
            }
            analysis_results.append(analysis)
            
            # Create discrepancy records if material
            if discrepancy_gl and abs(discrepancy_gl) >= Decimal(str(materiality_threshold)):
                discrepancies.append({
                    'account_number': account_number,
                    'account_name': account_name,
                    'discrepancy_type': 'GL',
                    'recorded_amount': float(gl_balance),
                    'calculated_amount': float(recalculated_balance),
                    'difference': float(discrepancy_gl)
                })
            
            if discrepancy_tb and abs(discrepancy_tb) >= Decimal(str(materiality_threshold)):
                discrepancies.append({
                    'account_number': account_number,
                    'account_name': account_name,
                    'discrepancy_type': 'TB',
                    'recorded_amount': float(tb_balance),
                    'calculated_amount': float(recalculated_balance),
                    'difference': float(discrepancy_tb)
                })
        
        logger.info(f"‚úÖ Analysis complete: {len(analysis_results)} accounts, {len(discrepancies)} discrepancies")
        
        return analysis_results, discrepancies
        
    except Exception as e:
        logger.error(f"‚ùå Analysis error: {str(e)}")
        raise


def generate_journal_entries(discrepancies):
    """Generate adjusting journal entries for discrepancies"""
    try:
        logger.info("üìù Generating journal entries...")
        
        journal_entries = []
        entry_number = 1
        
        for disc in discrepancies:
            adjustment_amount = abs(disc['difference'])
            entry_id = f"AJE-{entry_number:03d}"
            
            # Determine expense account
            account_name_lower = disc['account_name'].lower()
            expense_account = '6000'  # Default
            expense_name = 'General Expense'
            
            if 'insurance' in account_name_lower:
                expense_account, expense_name = '6100', 'Insurance Expense'
            elif 'rent' in account_name_lower:
                expense_account, expense_name = '6200', 'Rent Expense'
            elif 'software' in account_name_lower or 'subscription' in account_name_lower:
                expense_account, expense_name = '6400', 'Software Expense'
            
            if disc['difference'] > 0:
                # Reduce prepaid expense (credit prepaid, debit expense)
                journal_entries.append({
                    'entry_number': entry_id,
                    'account_number': disc['account_number'],
                    'account_name': disc['account_name'],
                    'debit': 0,
                    'credit': adjustment_amount,
                    'description': f"Adjustment to reduce prepaid expense per analysis"
                })
                journal_entries.append({
                    'entry_number': entry_id,
                    'account_number': expense_account,
                    'account_name': expense_name,
                    'debit': adjustment_amount,
                    'credit': 0,
                    'description': f"Expense recognition adjustment"
                })
            else:
                # Increase prepaid expense (debit prepaid, credit expense)
                journal_entries.append({
                    'entry_number': entry_id,
                    'account_number': disc['account_number'],
                    'account_name': disc['account_name'],
                    'debit': adjustment_amount,
                    'credit': 0,
                    'description': f"Adjustment to increase prepaid expense per analysis"
                })
                journal_entries.append({
                    'entry_number': entry_id,
                    'account_number': expense_account,
                    'account_name': expense_name,
                    'debit': 0,
                    'credit': adjustment_amount,
                    'description': f"Expense reversal adjustment"
                })
            
            entry_number += 1
        
        logger.info(f"‚úÖ Generated {len(journal_entries)} journal entry lines")
        return journal_entries
        
    except Exception as e:
        logger.error(f"‚ùå Journal entry generation error: {str(e)}")
        raise


def generate_excel_reports(analysis_results, discrepancies, journal_entries, session_id, client_name):
    """Generate Excel reports"""
    try:
        logger.info("üìä Generating Excel reports...")
        
        output_folder = os.path.join(app.config['UPLOAD_FOLDER'], session_id)
        os.makedirs(output_folder, exist_ok=True)
        
        reports = []
        
        # Report 1: Analysis Summary
        analysis_df = pd.DataFrame(analysis_results)
        analysis_file = os.path.join(output_folder, f"{client_name}_Prepaid_Analysis_{session_id}.xlsx")
        with pd.ExcelWriter(analysis_file, engine='openpyxl') as writer:
            analysis_df.to_excel(writer, sheet_name='Analysis Summary', index=False)
        reports.append(analysis_file)
        logger.info(f"‚úÖ Created: {os.path.basename(analysis_file)}")
        
        # Report 2: Discrepancies
        if discrepancies:
            discrepancies_df = pd.DataFrame(discrepancies)
            discrepancies_file = os.path.join(output_folder, f"{client_name}_Discrepancies_{session_id}.xlsx")
            with pd.ExcelWriter(discrepancies_file, engine='openpyxl') as writer:
                discrepancies_df.to_excel(writer, sheet_name='Discrepancies', index=False)
            reports.append(discrepancies_file)
            logger.info(f"‚úÖ Created: {os.path.basename(discrepancies_file)}")
        
        # Report 3: Journal Entries
        if journal_entries:
            je_df = pd.DataFrame(journal_entries)
            je_file = os.path.join(output_folder, f"{client_name}_Journal_Entries_{session_id}.xlsx")
            with pd.ExcelWriter(je_file, engine='openpyxl') as writer:
                je_df.to_excel(writer, sheet_name='Proposed AJEs', index=False)
            reports.append(je_file)
            logger.info(f"‚úÖ Created: {os.path.basename(je_file)}")
        
        return reports
        
    except Exception as e:
        logger.error(f"‚ùå Report generation error: {str(e)}")
        raise


# ============================================================================
# API ENDPOINTS (FIXED)
# ============================================================================

@app.route('/api/v1/info', methods=['GET'])
def get_info():
    """Get tool information"""
    return jsonify({
        'tool_id': 'prepaid_expense_analysis',
        'name': 'Prepaid Expense Analysis',
        'version': '1.0.0',
        'description': 'Analyze prepaid expenses by comparing GL, TB, and invoice data',
        'category': 'audit',
        'required_files': ['gl_file', 'tb_file', 'invoice_file'],
        'optional_params': {
            'client_name': 'Client name for report (default: Client)',
            'materiality_threshold': 'Threshold for flagging discrepancies (default: 100.00)'
        },
        'outputs': [
            'Analysis_Summary.xlsx',
            'Discrepancies.xlsx',
            'Proposed_Journal_Entries.xlsx'
        ],
        'author': 'Harshwal Consulting Services',
        'port': 5013
    })


@app.route('/api/v1/execute', methods=['POST'])
def execute_analysis():
    """
    Main execution endpoint
    
    Required files:
    - gl_file: General Ledger (Excel/CSV)
    - tb_file: Trial Balance (Excel/CSV)
    - invoice_file: Invoices (Excel/CSV)
    
    Optional parameters:
    - client_name: Client name (default: "Client")
    - materiality_threshold: Discrepancy threshold (default: 100.00)
    """
    try:
        logger.info("=" * 70)
        logger.info("PREPAID EXPENSE ANALYSIS - API EXECUTION")
        logger.info("=" * 70)
        
        # Validate files
        if 'gl_file' not in request.files:
            return jsonify({
                'success': False,
                'error': 'Missing required file: gl_file',
                'error_type': 'missing_file'
            }), 400
        
        if 'tb_file' not in request.files:
            return jsonify({
                'success': False,
                'error': 'Missing required file: tb_file',
                'error_type': 'missing_file'
            }), 400
        
        if 'invoice_file' not in request.files:
            return jsonify({
                'success': False,
                'error': 'Missing required file: invoice_file',
                'error_type': 'missing_file'
            }), 400
        
        gl_file = request.files['gl_file']
        tb_file = request.files['tb_file']
        invoice_file = request.files['invoice_file']
        
        # Validate file types
        if not allowed_file(gl_file.filename):
            return jsonify({
                'success': False,
                'error': f'Invalid GL file type: {gl_file.filename}',
                'error_type': 'invalid_file_type'
            }), 400
        
        if not allowed_file(tb_file.filename):
            return jsonify({
                'success': False,
                'error': f'Invalid TB file type: {tb_file.filename}',
                'error_type': 'invalid_file_type'
            }), 400
        
        if not allowed_file(invoice_file.filename):
            return jsonify({
                'success': False,
                'error': f'Invalid Invoice file type: {invoice_file.filename}',
                'error_type': 'invalid_file_type'
            }), 400
        
        # Get parameters
        client_name = request.form.get('client_name', 'Client')
        materiality_threshold = float(request.form.get('materiality_threshold', 100.00))
        
        logger.info(f"üìä Parameters:")
        logger.info(f"   Client: {client_name}")
        logger.info(f"   Materiality: ${materiality_threshold:,.2f}")
        
        # Create session
        session_id = f"prepaid_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        upload_folder = os.path.join(app.config['UPLOAD_FOLDER'], session_id)
        os.makedirs(upload_folder, exist_ok=True)
        
        # Save uploaded files
        gl_filename = secure_filename(gl_file.filename)
        tb_filename = secure_filename(tb_file.filename)
        invoice_filename = secure_filename(invoice_file.filename)
        
        gl_filepath = os.path.join(upload_folder, gl_filename)
        tb_filepath = os.path.join(upload_folder, tb_filename)
        invoice_filepath = os.path.join(upload_folder, invoice_filename)
        
        gl_file.save(gl_filepath)
        tb_file.save(tb_filepath)
        invoice_file.save(invoice_filepath)
        
        # Process files
        gl_data = process_gl_file(gl_filepath)
        tb_data = process_tb_file(tb_filepath)
        invoice_data = process_invoice_file(invoice_filepath)
        
        # Run analysis
        analysis_results, discrepancies = analyze_prepaid_expenses(
            gl_data, tb_data, invoice_data, materiality_threshold
        )
        
        # Generate journal entries
        journal_entries = generate_journal_entries(discrepancies)
        
        # Generate Excel reports
        reports = generate_excel_reports(
            analysis_results, discrepancies, journal_entries,
            session_id, client_name
        )
        
        # Build download URLs
        download_urls = [
            f"/api/v1/download/{session_id}/{os.path.basename(report)}"
            for report in reports
        ]
        
        # Store session data
        SESSIONS[session_id] = {
            'client_name': client_name,
            'materiality_threshold': materiality_threshold,
            'gl_records': len(gl_data),
            'tb_records': len(tb_data),
            'invoice_records': len(invoice_data),
            'accounts_analyzed': len(analysis_results),
            'discrepancies_found': len(discrepancies),
            'journal_entries_generated': len(journal_entries),
            'reports': reports
        }
        
        logger.info("=" * 70)
        logger.info("‚úÖ ANALYSIS COMPLETED SUCCESSFULLY")
        logger.info("=" * 70)
        
        return jsonify({
            'success': True,
            'session_id': session_id,
            'summary': {
                'client_name': client_name,
                'gl_records': len(gl_data),
                'tb_records': len(tb_data),
                'invoice_records': len(invoice_data),
                'accounts_analyzed': len(analysis_results),
                'discrepancies_found': len(discrepancies),
                'journal_entries_generated': len(journal_entries)
            },
            'result': {
                'success': True,
                'download_urls': download_urls
            }
        }), 200
        
    except Exception as e:
        logger.error(f"‚ùå Execution error: {str(e)}")
        logger.error(traceback.format_exc())
        return jsonify({
            'success': False,
            'error': str(e),
            'error_type': 'execution_error'
        }), 500


@app.route('/api/v1/download/<session_id>/<filename>', methods=['GET'])
def download_file(session_id, filename):
    """Download generated Excel file"""
    try:
        if session_id not in SESSIONS:
            return jsonify({
                'success': False,
                'error': 'Session not found'
            }), 404
        
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], session_id, filename)
        
        if not os.path.exists(filepath):
            return jsonify({
                'success': False,
                'error': 'File not found'
            }), 404
        
        return send_file(
            filepath,
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name=filename
        )
        
    except Exception as e:
        logger.error(f"Download error: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ‚úÖ FIXED: Health check endpoint matching tool_catalog.yaml
@app.route('/api/v1/health', methods=['GET'])
def health_check():
    """Health check endpoint - FIXED to match catalog"""
    return jsonify({
        'status': 'healthy',
        'tool': 'prepaid_expense_analysis',
        'port': 5013,
        'version': '1.0.0',
        'timestamp': datetime.now().isoformat()
    }), 200


# ============================================================================
# MAIN
# ============================================================================

if __name__ == '__main__':
    logger.info("=" * 70)
    logger.info("üöÄ PREPAID EXPENSE ANALYSIS API - STARTING")
    logger.info("=" * 70)
    logger.info("üìç Port: 5013")
    logger.info("üîó Health: http://localhost:5013/api/v1/health")
    logger.info("üîó Info: http://localhost:5013/api/v1/info")
    logger.info("=" * 70)
    
    app.run(
        host='0.0.0.0',
        port=5013,
        debug=False
    )